---
title: "bdacars"
output:
  html_document:
    df_print: paged
---

## Introduction

If you're reading this, you have probably heard about mtcars. If not, you're about to.

Originally extracted from the US magazine Motor Trend in the 1970s, this dataset of car performance and design information has inspired a load of applications of statistical models, notably in regression. For some reason, we have never actually analyzed this dataset on any course before, and now is our chance to take a swing at it. The Bayesian way. Let's see what we have on our hands:

### The dataset

The dataset consists of 32 cars, for which the following information has been recorded:

- Miles per gallon  (a measure of fuel consumption)
- Number of cylinders
- Displacement (the total volume of the cylinders)
- Gross horsepower
- Rear axle ratio (related to towing capabilities)
- Weight
- ¼ mile time (how fast the car can traverse a quarter mile)
- shape of the engine – straight vs V-shaped
- Transmission  - automatic vs manual
- Number of forward gears
- Number of carburetors

The dataset naturally calls for a regression model to study the effect of car design choices on fuel consumption. Here's our approach:

### The analysis problem

We will analyze three different factors potentially affecting fuel consumption: car weight, displacement and transmission. We hypothesize that heavier cars with bigger engines should consume more fuel i.e. they should have a lower miles per gallon (mpg) score. Altough we do assume that weight and displacement are correlated, so it'll be interesting to see how we can separate the two effects.  We also hypothesize that automatic cars consume less fuel than manual cars, since the automatic gearbox can optimize gears used better than a human driver.

To find out which of the three variables best predict fuel consumption, we will try four different models: one model for each pair of predictors and a model with all three included. We will then choose the best model and continue with the analysis.

### Unit conversions

The dataset is quite clean: no missing data or any nasty things to deal with. There is one problem we need to tackle right away, though. The units. Miles per gallon is not very easy to interpret to a Finnish person, especially because we are used to measuring fuel consumption directly, instead of measuring how far we can get with a fixed volume of fuel. Also, car displacement is recorded in cubic inches and car weight in pounds. Yep, the first step is to convert them to Finnish units so we don't need to do mental work interpreting every single figure and coefficient. Here are the conversions:

- Fuel consumption: Miles per US gallon $\rightarrow$ litres per 100 km
- Weight: 1000 pounds $\rightarrow$ metric tons (1000 kg)
- Displacement: Cubic inches $\rightarrow$ litres

Before deciding on further preprocessing steps, we need to emplore the data a bit.

## Exploratory analysis

Setting up libraries and the project path:

```{r, message=FALSE}
library(rstan)
library(GGally)
library(dplyr)
library(loo)
library(gridExtra)
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
path <- "~/Google_Drive/Kurssit/BDA/project/bdacars/"
source(paste0(path, "functions.R"))
```

Apply the unit conversions:

```{r}
propercars <- data.frame(wt = mtcars$wt/2.205,
                         disp = mtcars$disp/61.024,
                         lp100km = 235.215/mtcars$mpg,
                         am = mtcars$am)
```

For clarity, the abbreviations for the variables we use are:  
- wt = weight
- disp = displacement
- lp100km = litres per 100 km
- am = type of gearbox, 0 = automatic, 1 = manual

Now that we got the units right, let's take a lok at the data! A good first step is to plot the variables against each other. The ```ggpairs``` function fomr the ```GGally``` package comes in handy:

```{r, fig.width=10, fig.height=10}
# Change am to factor for correct plotting
plotcars <- propercars
plotcars$am <- factor(propercars$am)
# Change default plots styled for the lower triangular of the plot matrix
lower <- list(continuous = "smooth",
                combo = "facetdensity")
# Plot pairs of variables against each other
ggpairs(plotcars,
        lower = lower,
        showStrips = TRUE,
        progress = FALSE,
        title = "Original data in Finnish units") +
  theme_bw()
```

The plot matrix is a lot to take in, so let's deal with it piece-by-piece.  
First, let's look at the third row. It displays fuel consumption as a function of the potential explanatory variables. Starting from the left, the first three plots show no surprises. Fuel consumption strongly correlates with car weight and displacement, and the distribution looks smooth with few cars deviating from the rest. The last plot, though, seems to contradict one our initial hypotheses, since manual cars (class 1) seem to have lower fuel consumption than automatic ones. The bottom row displays a closer view at the distribution of the consumption in the two gearbox classes. The distribution of automatic cars seems to follow the overall distribution, while cars with low fuel consumption dominate the manual class.  We'll have to come back to this later!

Next up, the top two rows where we observe the relationships between our potential explanatory variables. The short story is : they're correlated. The Pearson correlation coefficient between weight and displacement is just shy of 0.9. In addition, automatic cars seem to be heavier an equipped with larger engines than manual cars. Maybe this explains their higher fuel consumption! We'll see after we run our models.

### Preprocessing

All the relationships in the data seem to be linear, so there is no clear need for non-linear transformation of variables. We will perform standard procedures of mean-centering and scaling by standard deviation before modeling. While mean centering does not change the regression coefficients, it makes the interpretation of the model intercepts more meaningful. Scaling by standard deviation in addition to mean centering makes our variables have mean 0 and standard deviation of 1. This will make choosing priors for the regression coefficients easier, as we know we are dealing with unit scale variables.

```{r}
# Only scale numeric variables
scaledcars <- propercars
scaledcars[1:3] <- scale(scaledcars[1:3])
```

We are now ready to move to the modeling part!

## Modeling

### Linear models

We performed bayesian linear regression, i.e. we will model fuel consumption using a linear models of form:
$$y \sim N(\alpha + \beta X,\, \sigma^2)$$
where $y$ is fuel consumption, $X$ is the matrix of predictor variables and $\alpha, \beta$ are the intercept and regression coefficients, respectively.

As mentioned before, we will try out four different models: one model for each pair of predictors and a model with all three included. We will then choose the best model and continue with the analysis.

### Priors

We use weakly informative priors, recommended as good default priors in [Stan prior choice recommendations](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations). The prior for $\alpha$ is a Cauchy distribution with center 0 and scale 10. As priors for the regression coefficients $\beta$ we use a Student's t distribution with 3 degrees of freedom, location 0 and scale 2. For the standard deviation of the posterior distribution, $\sigma$ we use a half-normal (0, 10) distribution.

The rule of thumb for weakly informative distributions is that the standard deviation of the posterior distribution should be less than 0.1 times that of the prior. The scales of the priors were chosen so that this rule is respected. To do this, we need to calculate the standard deviation of the prior. For a t-distribution with scale $s$ and $\nu$ degrees of freedom, the standard deviation is:
$$\sqrt{s^2\cdot \frac{\nu}{\nu -2}} = \sqrt{2^2 * \frac{3}{3-2}} = 2\cdot\sqrt{3} \approx 3.46$$
For a Cauchy distribution, the standard deviation is not defined, and for the normal prior of $\sigma$ we use standard deviation of 10.


### Stan model

The Stan code for the model with all the three predictors included looks like this:

```{stan, output.var="esa", eval=FALSE}
data {
  int<lower=0> n;
  vector[n] wt;
  vector[n] disp;
  vector[n] am;
  vector[n] lp100km;
}

// We name the components of beta explicitly
// While a bit cumbersome, this helps interpretation
// and lowers chances of error
parameters {
  real alpha;
  real beta_wt;
  real beta_disp;
  real beta_am;
  real<lower=0> sigma;
}
// The conditional mean for the linear model
transformed parameters{
  vector[n] mu;
  mu = alpha + beta_wt*wt + beta_disp*disp + beta_am*am;
}

model {
  // Priors
  alpha ~ cauchy(0,10);
  beta_wt ~ student_t(3,0,2);
  beta_disp ~ student_t(3,0,2);
  beta_am ~ student_t(3,0,2);
  sigma ~ normal(0, 10);
  // The linear model
  lp100km ~ normal(mu, sigma);
}

// Log likelihoods genereated for LOO
generated quantities {
  vector[n] log_lik;
  for (i in 1:n)
    log_lik[i] = normal_lpdf(lp100km[i] |mu[i] , sigma);
}
```

The other models are identical, with one of the predictor variables removed.

It is about time we see some results. Let's set up the data into a Stan-friendly format:

```{r}
dada <- list(lp100km = scaledcars$lp100km,
             wt=scaledcars$wt,
             disp = scaledcars$disp,
             am = scaledcars$am,
             n = nrow(scaledcars))
```

And run the Stan models:

```{r, echo = T, results = 'hide'}
model_names <- c("wt_disp", "wt_am", "disp_am", "wt_disp_am")
models <- list()

for(mname in model_names){
  fit <- stan(paste0(path, "stan_models/", mname,".stan"), data=dada, model_name = mname, seed = 38)
  models[[mname]] <- fit
}
```

Before comparing the performance of the models, we need to ensure a fair contest by checking that all of them have converged. Hear are the basic model summaries:

```{r, results='asis'}
for(mname in model_names){
  # Extract convergence diagnostics from the model
  smry <- model_summary(models[[mname]], mname)
  # Output as a nice table
  print(knitr::kable(smry, caption = paste("lp100km ~", gsub("_", " + ", mname))))
}
```

Since all the $\hat{R}$ values are close to 1, we can conclude that all the models have converged. We can now compare the models to find the best model for further analysis. In addition, the standard deviations of all the parameters are below 0.1 times the standard deviations of the priors, as we wanted.



### Model comparison:

We will use leave-one-out cross validation (LOO-cv) to compare the performance of the models:

```{r}
# Initialize
psisloos <- c()
p_effs <- c()
k_plots <- list()
for(mname in model_names){
  # Run LOO-cv
  loglik <- extract_log_lik(models[[mname]], merge_chains = FALSE)
  r_eff <- relative_eff(exp(loglik))
  loocv <- suppressWarnings(loo(loglik, r_eff = r_eff))
  
  # PSIS-LOO value
  psisloo <- loocv$estimates[1]
  # Effective parameters
  p_eff <- loocv$estimates[2]
  # k-values
  kval <- loocv$diagnostics$pareto_k
  
  # Combine results from the models
  p_effs <- c(p_effs, p_eff)
  psisloos <- c(psisloos, psisloo)
  
  # Plot of k-values
  kvals <- data.frame(k = kval,
                      x = 1:length(kval))
  p <- ggplot(data=kvals, aes(x=x, y=k)) +
    geom_point(color = 'red') +
    geom_hline(yintercept=0.5, color = 'blue') +
    ggtitle(mname) +
    xlab("") +
    ylab("k-value") +
    theme_bw()
  k_plots <- c(k_plots, list(p))
}
```

The first step is to see if the k-values of LOO-cv are low enough so that we can trust the results:

```{r, fig.width=10, fig.height=10}
# Combine plots of the k-values
grid.arrange(k_plots[[1]], k_plots[[2]], k_plots[[3]], k_plots[[4]], nrow=4, ncol=1)
```

With a few exceptions, most of the k-values seem to be low enough so that we can trust the results. The only one of the models that is raising some concern is the one with all the explanatory variables.

Next, enter drumroll, let's look at the PSIS-LOO values. The higher the value, the better the performance of the model. Winner takes it all, other models are discarded before we continue any further.


```{r}
psisloosdf <- data.frame(psisloo = psisloos,
                          model = model_names)
ggplot(data=psisloosdf, aes(x=model, y=psisloo)) + geom_bar(stat="identity", width=0.5) +
   geom_hline(yintercept=max(psisloos), color = 'blue')
```

```{r}
knitr::kable(psisloosdf %>%  arrange(desc(psisloo)),
             caption = "PSIS-LOO values")
```

The best model is the one with only weight and displacement as predictors, and adding gearbox type to the predictors does not improve performance. So it seems that the difference in fuel consumption between automatic and manual cars was indeed primarily due to the fact that the automatic cars were heavier and equipped with larger engines. Or at least we would need a more diverse dataset to make inferences about the effect of the gearbox.


Let's continue analysis with the best model.

```{r}
fit <- models[["wt_disp"]]
```

Since we only have two regression coefficients, it is easy for us to visualize the parameter space:

```{r}
fit_df <- as.data.frame(fit)[1:4]

ggplot(fit_df, aes(beta_wt, beta_disp, color=sigma)) +
  geom_point(alpha = 0.3) +
  geom_density2d(color = "white") +
  scale_color_viridis_c(option = 'inferno') +
  labs(title = 'Stan parameter space') +
  theme_bw()
```

There is a negative correlation between the two parameters, which makes sense, since if one of the predictors has a high coefficient, there is not much variation of fuel consumption left for the other predictor to explain (remember that the predictors weight and displacement are themselves heavily correlated).

Let's look at the individual distributions of the parameters:

```{r, fig.width=10, fig.height=4}
wt_p <- ggplot(fit_df, aes(beta_wt)) +
  geom_histogram(bins = 50, fill = "grey70", color = "grey50") +
  theme_bw()

disp_p <- ggplot(fit_df, aes(beta_disp)) +
  geom_histogram(bins = 50, fill = "grey70", color = "grey50") +
  theme_bw()

grid.arrange(wt_p, disp_p, ncol = 2)
```

For both of the regression coefficients, the vast majority of the draws are positive. To get a numeric estimate of the relevance of the two paramters, let's take a closer look at the summary statistics of the model:

```{r}
beta_smry <- summary(fit, pars = c("beta_wt", "beta_disp"))$summary
knitr::kable(beta_smry, digits = 3)
```

We also want to know the probabiliity that heavier cars and larger engines make the fuel consumption higher:

```{r}
fit_df %>% select(beta_wt, beta_disp) %>% sapply(function(x){sum(x > 0)/length(x)})
```

Unsurprisingly, we can conclude that  both weight and displacement are related to fuel consumption with a very high probability. But what about the effect size? We have so far only reported the effect size in the scaled units. It is not sufficient to know that heavier cars consume more fuel, we want to know _how much more_. Let's take some key statistics of the last table and transform them back to the original units.

```{r}
# Compute standard deviations of the predictors
sds <- sapply(propercars[c("wt", "disp", "lp100km")], sd)
# Scale back to original units
orig_smry <- beta_smry[, c(1, 4:8)]
orig_smry[1,] <- orig_smry[1,]/sds["wt"] * sds["lp100km"]
orig_smry[2,] <- orig_smry[2,]/sds["disp"] * sds["lp100km"]
knitr::kable(orig_smry, digits = 3)
```

Now this is easier to interpret! So an increase of a ton in car weight will on average cause an increase of approximately 4.5 liters per 100 km in fuel consumption. Meanwhile, increasing engine displacement by one litre results in an increase of approximately 0.8 litres per 100km in fuel consumption. 